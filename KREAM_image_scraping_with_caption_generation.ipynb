{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ba839f1-32d9-4ad5-b973-99d0d2c1f129",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d5d984f-613e-42b2-a3e6-03f89ffb81e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import psycopg2 as pg\n",
    "import pandas.io.sql as psql\n",
    "from datetime import date\n",
    "import datetime as dt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e559b2bc-3676-48a3-a457-ec5663d0473a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8164e45-2bb8-4acf-9945-5baa88383fdf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping main page: https://kream.co.kr/social/tags/ootd\n",
      "Number of post links found: 1923\n",
      "Scraping post: https://kream.co.kr/social/posts/1246114\n",
      "Successfully appended https://kream.co.kr/social/posts/1246114\n"ï¼Œ
      "Error scraping post https://kream.co.kr/social/posts/1236948: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF63B2F1F22+60322]\n",
      "\t(No symbol) [0x00007FF63B26CE99]\n",
      "\t(No symbol) [0x00007FF63B127EBA]\n",
      "\t(No symbol) [0x00007FF63B177676]\n",
      "\t(No symbol) [0x00007FF63B17773C]\n",
      "\t(No symbol) [0x00007FF63B1BE967]\n",
      "\t(No symbol) [0x00007FF63B19C25F]\n",
      "\t(No symbol) [0x00007FF63B1BBC80]\n",
      "\t(No symbol) [0x00007FF63B19BFC3]\n",
      "\t(No symbol) [0x00007FF63B169617]\n",
      "\t(No symbol) [0x00007FF63B16A211]\n",
      "\tGetHandleVerifier [0x00007FF63B60946D+3301613]\n",
      "\tGetHandleVerifier [0x00007FF63B653693+3605267]\n",
      "\tGetHandleVerifier [0x00007FF63B649410+3563664]\n",
      "\tGetHandleVerifier [0x00007FF63B3A42F6+790390]\n",
      "\t(No symbol) [0x00007FF63B2774DF]\n",
      "\t(No symbol) [0x00007FF63B2733D4]\n",
      "\t(No symbol) [0x00007FF63B273562]\n",
      "\t(No symbol) [0x00007FF63B262F6F]\n",
      "\tBaseThreadInitThunk [0x00007FFC21DF7344+20]\n",
      "\tRtlUserThreadStart [0x00007FFC230626B1+33]\n",
      "\n",
      "Failed to scrape https://kream.co.kr/social/posts/1236948\n",
      "Scraping post: https://kream.co.kr/social/posts/1236944\n",
      "Successfully appended https://kream.co.kr/social/posts/1236944\n",
      "...",
      "Successfully appended https://kream.co.kr/social/posts/1168848\n"
     ]
    }
   ],
   "source": [
    "scrolls = 150 \n",
    "main_url = 'https://kream.co.kr/social/tags/ootd'\n",
    "\n",
    "\n",
    "def scrape_post(driver, post_url):\n",
    "    try:\n",
    "        print(f\"Scraping post: {post_url}\")\n",
    "        driver.get(post_url)\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'full_width'))) \n",
    "        time.sleep(10)  # adding sleep to ensure page loads\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        pagination = soup.find('div', {'class': 'flicking-pagination'})\n",
    "        num_images = len(pagination.find_all('span', {'class': 'flicking-pagination-bullet'})) if pagination else 1\n",
    "\n",
    "        image_elements = soup.find_all('picture', {'class': 'social_img'})[:num_images]\n",
    "        image_urls = [img.find('img')['src'] for img in image_elements]\n",
    "\n",
    "        caption = soup.find('div', {'class': 'social_text'}).get_text(strip=True)\n",
    "        username = soup.find('span', {'class': 'user_name'}).get_text(strip=True)\n",
    "\n",
    "        product_links = [f\"https://kream.co.kr{link['href']}\" for link in soup.find_all('a', {'class': 'product_link'})]\n",
    "        product_links_str = ', '.join(product_links)\n",
    "\n",
    "        return {\n",
    "            'post_url': post_url,\n",
    "            'image_urls': ', '.join(image_urls),\n",
    "            'caption': caption,\n",
    "            'username': username,\n",
    "            'product_links': product_links_str\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping post {post_url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def scrape_main_page(driver, main_url, scroll_to_end=True, scroll_count=5):\n",
    "    driver.get(main_url)\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'full_width'))) \n",
    "\n",
    "    print(f\"Scraping main page: {main_url}\")\n",
    "\n",
    "    visited_post_urls = set()\n",
    "\n",
    "    if scroll_to_end:\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        while True:\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(10)\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "    else:\n",
    "        for _ in range(scroll_count): # to scroll X times\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(10)\n",
    "\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    post_links = soup.find_all('a', href=re.compile('/social/posts/'))\n",
    "\n",
    "    print(f\"Number of post links found: {len(post_links)}\")\n",
    "    \n",
    "    post_urls = []\n",
    "    for link in post_links:\n",
    "        post_url = f\"https://kream.co.kr{link['href']}\"\n",
    "        if post_url not in visited_post_urls:\n",
    "            visited_post_urls.add(post_url)\n",
    "            post_urls.append(post_url)\n",
    "\n",
    "    return post_urls\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# edit scroll to end or scroll count HERE\n",
    "post_urls = scrape_main_page(driver, main_url, scroll_to_end=False, scroll_count=scrolls)\n",
    "all_data = []\n",
    "\n",
    "for url in post_urls:\n",
    "    post_data = scrape_post(driver, url)\n",
    "    if post_data:\n",
    "        all_data.append(post_data)\n",
    "        print(f\"Successfully appended {url}\")\n",
    "    else:\n",
    "        print(f\"Failed to scrape {url}\")\n",
    "        \n",
    "df = pd.DataFrame(all_data)\n",
    "df.to_csv('scraped_data3.csv', index=False, encoding='utf-8') # if want to store as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35737644-5fe4-431f-9f8b-6e8a6508ff0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1 = df\n",
    "df1 = df1.drop(['post_url','caption'], axis = 1)\n",
    "\n",
    "# keep only first picture per post\n",
    "df1['image_urls'] = df1['image_urls'].str.extract(r'^([^,]*)')\n",
    "df1['product_links'] = df1['product_links'].str.extract(r'^([^,]*)')\n",
    "df1['image_urls'] = df1['image_urls'].fillna(df1['image_urls'])\n",
    "df1['product_links'] = df1['product_links'].fillna(df1['product_links'])\n",
    "\n",
    "# if want all pictures per post\n",
    "# df1['image_urls'] = df1['image_urls'].str.split(', ')\n",
    "# df1['product_links'] = df1['product_links'].str.split(', ')\n",
    "# df2 = df1.explode('image_urls', ignore_index = True)\n",
    "# df2 = df2.explode('product_links', ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c2747e-317a-4fa1-a47d-56c39106d25d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Linking With Internal Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7bea9f8-5156-489a-98f7-896cc1547963",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m DbMain \u001b[38;5;241m=\u001b[39m pg\u001b[38;5;241m.\u001b[39mconnect(\n\u001b[0;32m      2\u001b[0m      host\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXXX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m      database\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYYY\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m      user\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZZZ\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m      password\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhihihi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m internal_AT \u001b[38;5;241m=\u001b[39m psql\u001b[38;5;241m.\u001b[39mread_sql(\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124mSELECT p.product_id as product_id, p.kream_url as product_links, p.product_name, p.mpn_sku, p.nickname, p.silhouette, p.browse_level_2, p.browse_level_3, p.browse_level_4 FROM product_base p\u001b[39m\u001b[38;5;124m'''\u001b[39m, DbMain)\n\u001b[0;32m      9\u001b[0m internal_AT \u001b[38;5;241m=\u001b[39m internal_AT\u001b[38;5;241m.\u001b[39mrename(columns \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_id\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduct ID\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pg' is not defined"
     ]
    }
   ],
   "source": [
    "DbMain = pg.connect(\n",
    "     host=\"XXX\",\n",
    "     database=\"YYY\",\n",
    "     user=\"ZZZ\",\n",
    "     password=\"hihihi\")\n",
    "\n",
    "# to join product_id via kream_url\n",
    "internal_AT = psql.read_sql('''\n",
    "SELECT p.product_id as product_id, p.kream_url as product_links, p.product_name, p.mpn_sku, p.nickname, p.silhouette, p.browse_level_2, p.browse_level_3, p.browse_level_4 FROM product_base p''', DbMain)\n",
    "internal_AT = internal_AT.rename(columns = {'product_id' : 'Product ID'})\n",
    "DbMain.close()\n",
    "\n",
    "# if there are duplicates, keep smaller product_id\n",
    "def keep_smaller_product_id(df):\n",
    "    duplicates = df[df.duplicated(subset='product_links', keep=False)]\n",
    "    duplicated_links = duplicates['product_links'].unique()\n",
    "    for link in duplicated_links:\n",
    "        subset = df[df['product_links'] == link]\n",
    "        # check\n",
    "        if subset['Product ID'].nunique() == len(subset):\n",
    "            min_product_id = subset['Product ID'].min()\n",
    "            df = df.drop(subset[subset['Product ID'] != min_product_id].index)\n",
    "    \n",
    "    return df\n",
    "\n",
    "internal_AT = keep_smaller_product_id(internal_AT)\n",
    "internal_AT = internal_AT[internal_AT['product_links'] != \"None\"]\n",
    "internal_AT = internal_AT.drop_duplicates(subset=['product_links'])\n",
    "internal_AT = internal_AT[internal_AT['product_links'] != \"None\"]\n",
    "\n",
    "# create a tagging name for caption generation\n",
    "def create_tagging_name(row):\n",
    "    mpn_sku = str(row['mpn_sku']) \n",
    "    product_name = row['product_name']\n",
    "    if mpn_sku == 'None':\n",
    "        return product_name\n",
    "    elif mpn_sku != 'None' and mpn_sku not in product_name:\n",
    "        return product_name\n",
    "    else:\n",
    "        return product_name.replace(mpn_sku, '').strip()\n",
    "\n",
    "internal_AT['tagging_name'] = internal_AT.apply(create_tagging_name, axis=1)\n",
    "internal_AT = internal_AT.drop(['product_name','mpn_sku'], axis = 1)\n",
    "internal_AT = internal_AT.drop_duplicates()\n",
    "\n",
    "final_df = pd.merge(df1, internal_AT, on = \"product_links\", how=\"left\")\n",
    "final_df1 = final_df[final_df['Product ID'].notna()]\n",
    "final_df1['Product ID'] = final_df1['Product ID'].astype(int)\n",
    "final_df1 = final_df1.drop(['product_links'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878a26ef-02ba-4fe7-a3da-5e74e3a0dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "urls = pd.read_csv(\"dataset_instagram-scraper_2024-03-07_07-34-28-256.csv\")\n",
    "ig_urls = urls['displayUrl'].tolist()\n",
    "\n",
    "# https://console.apify.com/actors/shu8hvrXbJbY3Eb9W/console\n",
    "import os\n",
    "import requests\n",
    "import uuid\n",
    "import time\n",
    "\n",
    "def download_image(url, save_directory, image_name):\n",
    "    response = requests.get(url)\n",
    "    time.sleep(2)\n",
    "    # Ensure the save directory exists\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "    \n",
    "    save_path = os.path.join(save_directory, image_name)\n",
    "    \n",
    "    with open(save_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "save_directory = \"pics\"\n",
    "\n",
    "\n",
    "for i, ig_url in enumerate(ig_urls, start = 1):\n",
    "    image_uuid = str(uuid.uuid4())\n",
    "    image_name = f\"Image{image_uuid}.jpg\"\n",
    "    \n",
    "    download_image(ig_url, save_directory, image_name)\n",
    "    print(f\"downloaded Image {i}\")\n",
    "    \n",
    "\n",
    "# Resize Image\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def resize_images(folder_path, target_width=750):\n",
    "    # Ensure the target folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Error: The folder '{folder_path}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    # Get a list of all files in the specified folder\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    for file in files:\n",
    "        # Check if the file is an image (you may need to add more image extensions)\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "\n",
    "            # Open the image\n",
    "            with Image.open(file_path) as img:\n",
    "                # Get the current width of the image\n",
    "                current_width = img.width\n",
    "\n",
    "                # Check if the width is less than the target width\n",
    "                if current_width < target_width:\n",
    "                    # Calculate the new height to maintain the aspect ratio\n",
    "                    aspect_ratio = img.height / img.width\n",
    "                    new_height = int(target_width * aspect_ratio)\n",
    "\n",
    "                    # Resize the image\n",
    "                    resized_img = img.resize((target_width, new_height))\n",
    "\n",
    "                    # Save the resized image, overwrite the original\n",
    "                    resized_img.save(file_path)\n",
    "\n",
    "                    print(f\"Resized '{file}' from {current_width}px to {target_width}px.\")\n",
    "                else:\n",
    "                    print(f\"'{file}' is already {current_width}px or larger. Skipped.\")\n",
    "\n",
    "# Call the function to resize images in the specified folder\n",
    "resize_images(save_directory)\n",
    "\n",
    "resize_images(\"C:/Users/novel/Documents/dashboard/pics/KREAM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ad6775-0946-459d-8ca4-787d8e97c292",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d91deb5-c1d5-4001-bb5d-959a8aef8ced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_df1['nickname'] = final_df1['nickname'].astype(str)\n",
    "final_df1['silhouette'] = final_df1['silhouette'].astype(str)\n",
    "final_df1['browse_level_2'] = final_df1['browse_level_2'].astype(str)\n",
    "final_df1['browse_level_3'] = final_df1['browse_level_3'].astype(str)\n",
    "final_df1['browse_level_2'] = final_df1['browse_level_4'].astype(str)\n",
    "final_df1['silhouette'] = final_df1['silhouette'].astype(str)\n",
    "final_df1['tagging_name'] = final_df1['tagging_name'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a9c8afa0-fa78-4222-8bba-454457bd2bc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def modify_tagging_name(row):\n",
    "    tagging_name = row['tagging_name']\n",
    "    nickname = row['nickname']\n",
    "    silhouette = row['silhouette']\n",
    "    browse_level_2 = row['browse_level_2']\n",
    "    browse_level_3 = row['browse_level_3']\n",
    "    browse_level_4 = row['browse_level_4']\n",
    "    if \"Nike\" in tagging_name:\n",
    "        if silhouette != \"None\":\n",
    "            return silhouette + \" \" + nickname\n",
    "        elif browse_level_2 != \"None\":\n",
    "            return browse_level_2 + \" \" + nickname\n",
    "        elif browse_level_3 != \"None\":\n",
    "            return \"Nike \" + browse_level_3 + \" \" + nickname\n",
    "        else:\n",
    "            return \"Nike \" + nickname\n",
    "    elif \"Jordan\" in tagging_name:\n",
    "        if silhouette != \"None\":\n",
    "            return silhouette + \" \" + nickname\n",
    "        elif browse_level_2 != \"None\":\n",
    "            return browse_level_2 + \" \" + nickname\n",
    "        elif browse_level_3 != \"None\":\n",
    "            return \"Jordan \" + browse_level_3 + \" \" + nickname\n",
    "        else:\n",
    "            return \"Jordan \" + nickname\n",
    "    elif \"New Balance\" in tagging_name:\n",
    "        numericals = re.findall(r'\\d+', tagging_name)\n",
    "        return \"New Balance \" + ' '.join(numericals)\n",
    "    elif \"Samba\" in tagging_name:\n",
    "        return \"Samba\"\n",
    "    elif 'Yeezy Slide' not in tagging_name and 'Yeezy GAP' not in tagging_name and 'Yeezy' in tagging_name:\n",
    "        numericals = re.findall(r'\\d+', tagging_name)\n",
    "        return \"Yeezy \" + ' '.join(numericals)\n",
    "    else:\n",
    "        return tagging_name\n",
    "    \n",
    "final_df1['product_name'] = final_df1.apply(modify_tagging_name, axis = 1)\n",
    "final_df1['product_name'] = final_df1['product_name'].str.replace('(Women)', '', regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd7b982-eb4e-43f2-b883-851cbd1628ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Caption Generator (GEMINI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c35f6b04-e949-48bb-b3cd-66c2d49087cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install -q -U google-generativeai\n",
    "\n",
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "def to_markdown(text):\n",
    "    text = text.replace('â€¢', '  *')\n",
    "\n",
    "    return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
    "\n",
    "GOOGLE_API_KEY = 'KEY_HERE'\n",
    "genai.configure(api_key = GOOGLE_API_KEY)\n",
    "\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "# to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f4d86b-b013-4e07-a63d-c580b5f92780",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FOR IMAGE-BASED\n",
    "# model = genai.GenerativeModel('gemini-pro-vision')\n",
    "# response = model.generate_content(prompt)\n",
    "# prompt = [f\"Write a short caption regarding this image related to fashion using first-person pronouns such as 'i', 'we', 'me', 'us', 'my'. \",\n",
    "#             f\"The caption should have a core message (examples: 'just copped', 'unboxed', 'obsessed with my new') \",\n",
    "#             f\" and mention the product name and details. It should also highlight features or colours, or share a story behind the purchase (examples: 'been waiting for these'). \",\n",
    "#             f\"The less words the better. The sentences must be complete sentences. Do not always start the caption with 'finally got' and do not always say 'unreal'\",\n",
    "#              f\"If the image appears overloaded with text resembling an advertisement or promotional material, such as the inclusion of words like 'sale', 'promotion', or a brand name, initiate the generation with the phrase 'AD ALERT'\"]\n",
    "# prompt = ''.join(prompt)\n",
    "# directory = 'C:Directory\\\\here'\n",
    "# def generate_caption(file_name, prompt, model):\n",
    "#     time.sleep(30)\n",
    "#     try:\n",
    "#         img = PIL.Image.open(directory + '\\\\' + file_name)\n",
    "#         response = model.generate_content([prompt, img], stream=True)\n",
    "#                                          # safety_settings = {'HARRASSMENT' : 'block_none',\n",
    "#                                          #                   'SEXUALLY_EXPLICITY' : 'block_none',\n",
    "#                                          #                   'HATE_SPEECH' : 'block_none',\n",
    "#                                          #                   'DANGEROUS_CONTENT' : 'block_none'})\n",
    "#         response.resolve()\n",
    "#         print(f\"done for {file_name}\")\n",
    "#         return response.text\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing image '{file_name}': {e}\")\n",
    "#         return None\n",
    "\n",
    "# final_df1['Caption'] = final_df1['File Name'].apply(lambda x: generate_caption(x, prompt, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4ebd73e9-c270-4934-9362-3fc843a4d567",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "Error: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n",
      "                                            image_urls        username  \\\n",
      "0    https://kream-phinf.pstatic.net/MjAyNDAyMjhfMj...           _rael   \n",
      "1    https://kream-phinf.pstatic.net/MjAyNDAyMjVfMj...           _rael   \n",
      "2    https://kream-phinf.pstatic.net/MjAyNDAyMjRfMT...           _rael   \n",
      "3    https://kream-phinf.pstatic.net/MjAyNDAyMjBfMj...     shoeperstar   \n",
      "4    https://kream-phinf.pstatic.net/MjAyNDAyMThfMT...           _rael   \n",
      "..                                                 ...             ...   \n",
      "782  https://drive.google.com/file/d/1G-0CjZOVa3UPE...  hoodrichh_bigt   \n",
      "783  https://drive.google.com/file/d/1IvRL2mrm2Ze6C...   i.am.biancaaa   \n",
      "784  https://drive.google.com/file/d/1ebPiuIjaSlMDK...  javithenics2.0   \n",
      "785  https://drive.google.com/file/d/109z7fA2NgH1Kq...    2beatzinapod   \n",
      "786  https://drive.google.com/file/d/1EUzEhMMZXI3-f...      mouthsplit   \n",
      "\n",
      "     Product ID                    nickname    silhouette browse_level_2  \\\n",
      "0        258411                       White     Superstar           None   \n",
      "1        363825           Black Pure Silver    Gel Kayano           None   \n",
      "2        273112                    Mid Grey          None           None   \n",
      "3         66129                        Blue       Gazelle           None   \n",
      "4         75983                        Grey           991           None   \n",
      "..          ...                         ...           ...            ...   \n",
      "782       65742                   True Blue  Jordan 1 Low            Low   \n",
      "783       75691                 Cement Grey     Jordan 11            Low   \n",
      "784       54279                     Shimmer      Jordan 4           None   \n",
      "785       29669                    Fearless  Jordan 1 Mid            Mid   \n",
      "786       67307  United Youth International      Jordan 2           None   \n",
      "\n",
      "    browse_level_3 browse_level_4  \\\n",
      "0             None           None   \n",
      "1             None           None   \n",
      "2             None           None   \n",
      "3             None           None   \n",
      "4             None           None   \n",
      "..             ...            ...   \n",
      "782       Jordan 1            Low   \n",
      "783      Jordan 11            Low   \n",
      "784       Jordan 4           None   \n",
      "785       Jordan 1            Mid   \n",
      "786       Jordan 2           None   \n",
      "\n",
      "                                          tagging_name  \\\n",
      "0                      CLOT x adidas Superstar 'White'   \n",
      "1              ASICS Gel Kayano 14 'Black Pure Silver'   \n",
      "2                 ASICS Gel-Quantum Kinetic \"Mid Grey\"   \n",
      "3            adidas x Gucci Gazelle 'Light Blue Suede'   \n",
      "4                    JJJJound x New Balance 991 'Gray'   \n",
      "..                                                 ...   \n",
      "782               Air Jordan 1 Low 'Indigo' DM1199â€‘140   \n",
      "783   Air Jordan 11 Retro Low 'Cement Grey' AV2187â€‘140   \n",
      "784    (Women) Air Jordan 4 Retro 'Shimmer' DJ0675â€‘200   \n",
      "785  Maison ChÃ¢teau Rouge x Air Jordan 1 Mid SE 'Fe...   \n",
      "786     Air Jordan 2 'Maison Chateau Rouge' DO5254â€‘180   \n",
      "\n",
      "                                  product_name  \\\n",
      "0              CLOT x adidas Superstar 'White'   \n",
      "1      ASICS Gel Kayano 14 'Black Pure Silver'   \n",
      "2         ASICS Gel-Quantum Kinetic \"Mid Grey\"   \n",
      "3    adidas x Gucci Gazelle 'Light Blue Suede'   \n",
      "4                              New Balance 991   \n",
      "..                                         ...   \n",
      "782                     Jordan 1 Low True Blue   \n",
      "783                      Jordan 11 Cement Grey   \n",
      "784                           Jordan 4 Shimmer   \n",
      "785                      Jordan 1 Mid Fearless   \n",
      "786        Jordan 2 United Youth International   \n",
      "\n",
      "                                               caption  \n",
      "0    I'm loving my new White! They're so crisp and ...  \n",
      "1    Obsessed with the Black Pure Silver ASICS Gel ...  \n",
      "2                                                 None  \n",
      "3    Finally got my hands on the amazing Adidas x G...  \n",
      "4    Finally got my hands on these Grey. Love the n...  \n",
      "..                                                 ...  \n",
      "782            True Blue's back in my hands. Obsessed.  \n",
      "783  Finally got my hands on Cement Grey Jordan 11s...  \n",
      "784                    Obsessed with my new Shimmer's.  \n",
      "785  Fearless is here. Super happy with my latest cop!  \n",
      "786  Jordan 2 United Youth International in hand an...  \n",
      "\n",
      "[787 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt function with f-string formatting\n",
    "def prompt(product_name, nickname):\n",
    "    text = (f\"Assume you are a happy customer that just got your fashion purchase of the product, {product_name}. \",\n",
    "            f\"Create a simple first-person caption in less than 20 words that is talking about the product. Use either {product_name} or {nickname} as the naming convention when referencing the product. \",\n",
    "            f\"Choose which naming convention would suit the caption best, but do not use both.\",\n",
    "            f\"using first-person pronouns such as 'i', 'we', 'me', 'us', 'my'. \",\n",
    "            f\"Use a random, casual persona and tone. \",\n",
    "            f\"The caption should have a core message (examples: 'just copped', 'unboxed', 'obsessed with my new', 'loving my new', 'finally got these', 'got my hands on these') \",\n",
    "            f\" and mention the product's details. It should also highlight features or colours, or share a story behind the purchase (examples: 'been waiting for these', 'finally got them'). \",\n",
    "            f\"Avoid using words like 'stepping out', 'fresh', 'rock', 'swag', 'rad', 'trendy', 'streetwear', 'slayin', 'rocking', 'vibes', 'raddest', 'dope', 'exuding', 'rhythm', 'effortless', 'chic', 'adventures', 'awesome', 'strut'. \",\n",
    "            f\"The less words the better. The sentences must be complete sentences. Do not always start the caption with 'finally got' and do not always say 'unreal'\")\n",
    "    text = \"\".join(text)\n",
    "    return text\n",
    "\n",
    "def generate_caption(data):\n",
    "    product_name = data['product_name']\n",
    "    nickname = data['nickname']\n",
    "    try:# Generate caption using the prompt\n",
    "        caption = model.generate_content(prompt(product_name, nickname)).text\n",
    "        return caption\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "    \n",
    "final_df1['caption'] = final_df1.apply(generate_caption, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645b9354-c29b-4ed3-9f94-5a778eb8cfd5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Randomizing Plus Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dfddab58-0c4b-4ddd-9e75-f595167d3ff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_df1['user_id'] = int(696772)\n",
    "final_df1['product_tag_id'] = final_df1['Product ID']\n",
    "export_df = final_df1[['user_id', 'username', 'caption', 'image_urls', 'product_tag_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a42688fd-6643-418c-ab0a-5749a6b467e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export_df = export_df.sample(frac=1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8497abf4-782f-40b2-9f99-f787abc75950",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Function to generate random times within a given range\n",
    "def generate_random_times(start_time, end_time, num_times):\n",
    "    time_diff = end_time - start_time\n",
    "    random_times = [start_time + timedelta(seconds=np.random.randint(time_diff.total_seconds())) for _ in range(num_times)]\n",
    "    return random_times\n",
    "\n",
    "# Define your initial fixed start and end dates and times\n",
    "fixed_start_date = datetime(2024, 6, 4)\n",
    "\n",
    "# Number of rows and rows per pattern\n",
    "total_rows = len(export_df)  # Replace with your desired total number of rows\n",
    "rows_per_pattern = 20\n",
    "\n",
    "# Calculate the number of patterns\n",
    "num_patterns = total_rows // rows_per_pattern\n",
    "\n",
    "\n",
    "# Initialize an empty list to hold pattern DataFrames\n",
    "pattern_dfs = []\n",
    "\n",
    "for pattern_num in range(num_patterns):\n",
    "    # Fixed start date for the pattern\n",
    "    start_date = fixed_start_date + timedelta(days=pattern_num)\n",
    "    \n",
    "    # Fixed start time for the pattern\n",
    "    start_time = start_date + timedelta(seconds=np.random.randint(86400))  # Random time within the day\n",
    "    \n",
    "    # Fixed end time for the pattern\n",
    "    end_time = start_time.replace(hour=23, minute=59, second=59)\n",
    "    \n",
    "    # Generate random times for the middle rows\n",
    "    random_times = generate_random_times(start_time, end_time, rows_per_pattern - 2)\n",
    "    \n",
    "    # Concatenate the times for the pattern\n",
    "    times_for_pattern = [start_time] + random_times + [end_time]\n",
    "    \n",
    "    # Create a DataFrame for the pattern\n",
    "    pattern_df = pd.DataFrame({'time_to_post': times_for_pattern})\n",
    "    \n",
    "    # Append the pattern DataFrame to the list\n",
    "    pattern_dfs.append(pattern_df)\n",
    "\n",
    "# Concatenate all pattern DataFrames along rows\n",
    "time_df = pd.concat(pattern_dfs, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f67dac65-9b7a-42ae-9146-4382301324b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export_df = pd.concat([export_df, time_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4888cd7f-1f3e-4ae5-b00e-000d7ff78b54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gspread\n",
    "import gspread_dataframe as gd\n",
    "\n",
    "gc1 = gspread.service_account('C:/Users/novel/Documents/dashboard/service_account.json')\n",
    "sh = gc1.open_by_url('https://docs.google.com/spreadsheets/d/1pbZ2rgePViErqW3JBhY7ExVvSsYOgYBimMP193y32mc/edit#gid=0')\n",
    "\n",
    "inj = sh.worksheet(\"Interject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b178080-4d0c-4a5a-93c0-b9801238e336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "inj_df = inj.get_all_records()\n",
    "inj_df = pd.DataFrame(inj_df)\n",
    "inj_df = inj_df.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f1ab90e-6bbd-48a3-9a16-8601ee878207",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "start_time = datetime.strptime('14:00', \"%H:%M\").time()\n",
    "end_time = datetime.strptime('22:00', \"%H:%M\").time()\n",
    "\n",
    "num_days = len(inj_df) // 20\n",
    "if len(inj_df) % 20 != 0:\n",
    "    num_days += 1\n",
    "\n",
    "# Generate random posting times for each day\n",
    "time_to_post_list = []\n",
    "for day in range(num_days):\n",
    "    current_date = datetime.today().date() + timedelta(days=1) + timedelta(days=day)\n",
    "    for _ in range(20):\n",
    "        random_time = datetime.combine(current_date, start_time) + timedelta(minutes=random.randint(0, 480))  # 480 minutes \n",
    "        time_to_post_list.append(random_time.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "# Shuffle the list of posting times to randomize the order\n",
    "random.shuffle(time_to_post_list)\n",
    "\n",
    "# Add the 'time_to_post' column to the DataFrame\n",
    "inj_df['time_to_post'] = time_to_post_list[:len(inj_df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88833466-2b26-4e75-a81b-e710ad50c0c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inj_df = inj_df.sort_values(by = 'time_to_post')\n",
    "gd.set_with_dataframe(inj, inj_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
